{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Learning for sample selection\n",
    "\n",
    "Active Learning can also be used to create a diverse and representative selection of the data, by using representation-based query strategies, without need of the labels and of a prediction/classification model. This can be very useful if our dataset is imbalanced, or if some outliers/extreme points are very significant to our analysis and we need to be sure to include them even if they are a minority, as random sampling is likely to overlook them.\n",
    "For this example we are going to use a subset of [_MNIST_](https://archive.ics.uci.edu/dataset/683/mnist+database+of+handwritten+digits) dataset, loaded from _sklearn_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from activelearning.AL_selection import selection_AL\n",
    "from activelearning.queries.representative.coreset_query import query_coreset\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to tensors of acceptable sizes for ResNet and normalize\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# import data\n",
    "train_full = datasets.MNIST(root=\"./data\", train=True, download=True, transform=preprocess)\n",
    "test_full = datasets.MNIST(root=\"./data\", train=False, download=True, transform=preprocess)\n",
    "\n",
    "# we are going to use a subset of 1500 images for this example\n",
    "y_train = train_full.targets[:1000,]\n",
    "y_test = test_full.targets[:500,]\n",
    "\n",
    "train = Subset(train_full, indices=range(1000))\n",
    "test = Subset(test_full, indices=range(500))\n",
    "\n",
    "# to use batches instead of one at a time\n",
    "loaded_train = DataLoader(train, batch_size=64, shuffle=False)\n",
    "loaded_test = DataLoader(test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_MNIST_ consists of images of handwritten digits from 0 to 9. When working with image data, we need to first extract features using for example a pretrained model. In this case, we will use [ResNet18](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html) for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ResNet model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# remove classification layer\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "# set to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(torch.device(device))\n",
    "\n",
    "train_features_list = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in loaded_train:\n",
    "        features_by_resnet = resnet(images.to(device))\n",
    "        train_features_list.append(features_by_resnet)\n",
    "\n",
    "test_features_list = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in loaded_test:\n",
    "        features_by_resnet = resnet(images.to(device))\n",
    "        test_features_list.append(features_by_resnet)\n",
    "\n",
    "\n",
    "train_features = torch.cat(train_features_list, dim=0).squeeze()\n",
    "\n",
    "train_features = train_features.cpu().numpy()\n",
    "\n",
    "test_features = torch.cat(test_features_list, dim=0).squeeze()\n",
    "test_features = test_features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare how different query strategies perform, we can use the *strategy_comparison* function and pass the strategies to be used. We can also pass more than one number of instances, to check whether a different batch size influences performance. *plot_results* can be used to immediatly plot the output from *strategy_comparison*, or a custom graph can be created from the scores data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data, selected_idxs = selection_AL(\n",
    "    X_train=None, X_pool=train_features, query_strategy=query_coreset, n_instances=1, n_queries=20\n",
    ")\n",
    "\n",
    "print(pd.Series(y_train[selected_idxs]).value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
